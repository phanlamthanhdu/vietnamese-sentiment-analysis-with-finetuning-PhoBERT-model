{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vietnamese_alphabet = [\n",
    "    'a', 'Ã ', 'Ã¡', 'áº£', 'Ã£', 'áº¡', 'Äƒ', 'áº¯', 'áº±', 'áº³', 'áºµ', 'áº·', 'Ã¢', 'áº¥', 'áº§', 'áº©', 'áº«', 'áº­',\n",
    "    'b', 'c', 'd', 'Ä‘', 'e', 'Ã¨', 'Ã©', 'áº»', 'áº½', 'áº¹', 'Ãª', 'áº¿', 'á»', 'á»ƒ', 'á»…', 'á»‡',\n",
    "    'f', 'g', 'h', 'i', 'Ã¬', 'Ã­', 'á»‰', 'Ä©', 'á»‹', 'k', 'l', 'm', 'n', 'o', 'Ã²', 'Ã³', 'á»', 'Ãµ', 'á»', 'Ã´', 'á»‘', 'á»“', 'á»•', 'á»—', 'á»™', 'Æ¡', 'á»›', 'á»', 'á»Ÿ', 'á»¡', 'á»£',\n",
    "    'p', 'q', 'r', 's', 't', 'u', 'Ã¹', 'Ãº', 'á»§', 'Å©', 'á»¥', 'Æ°', 'á»©', 'á»«', 'á»­', 'á»¯', 'á»±',\n",
    "    'v', 'w', 'x', 'y', 'á»³', 'Ã½', 'á»·', 'á»¹', 'á»µ', 'z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_removal(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    pattern = r\"[^{vi_alpha}\\d=<>\\\"\\':/%$+&,.() ]\".format(vi_alpha = \"\".join(vietnamese_alphabet))\n",
    "    result = re.sub(pattern, '', text)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_normalization(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    pattern = r\"[\\-=<>\\\"\\':/%$+&,.()]\"\n",
    "    matches = re.finditer(pattern, text) \n",
    "    text = list(text)\n",
    "    \n",
    "    for match in matches:\n",
    "        text[match.start()] = ' ' + text[match.start()] + ' '\n",
    "    return \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_normalization(text: str) -> str:\n",
    "    pattern = r\"[ ]+\"\n",
    "    result = re.sub(pattern,' ',text)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'diner-reviews.txt'\n",
    "with open(fileName,'r') as readFile:\n",
    "    reviewList = [ast.literal_eval(ele.strip()) for ele in readFile.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(text: str) -> str:\n",
    "    text = emoji_removal(text)\n",
    "    text = punctuation_normalization(text)\n",
    "    text = space_normalization(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bÃ¡nh canh cua ngon & giÃ¡ á»•n mÃ¬nh tháº¥y review á»Ÿ Ä‘Ã¢y cÃ³ ná»“i bÃ¡nh canh cua lÃ  láº¡ nÃªn láº·n lá»™i xÆ¡i ha Ä‘á»ƒ Ä‘i thá»­ quÃ¡n náº±m trong háº»m , mÃ  theo map cÅ©ng dá»… kiáº¿m láº¯m Ã  ná»“i bÃ¡nh canh hoÃ nh trÃ¡ng láº¯m . topping ngáº­p máº·t , toÃ n mÃ³n cháº¥t lÆ°á»£ng . tÃ´m to , cháº£ cÃ¡ , trá»©ng cÃºt , thá»‹t nÃªm náº¿m ráº¥t á»•n má»™t ná»“i 92k cÃ³ thá»ƒ Äƒn 2 ngÆ°á»i ( no cÄƒng ) hoáº·c 3 ngÆ°á»i náº¿u Äƒn Ã­t chÃºt . gá»i thÃªm Ä‘Ä©a quáº©y 10k mÃ¬nh ghÃ© táº§m 5h chiá»u ngÃ y thÆ°á»ng , quÃ¡n Ä‘Ã´ng . phá»¥c vá»¥ nhanh gá»n team mÃª bÃ¡nh canh cua lÃ  pháº£i thá»­ nha . xa nhÃ  quÃ¡ , chá»© ko mÃ¬nh ghÃ© hoÃ i '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization(\"BÃ¡nh canh cua ngon & giÃ¡ á»•n \\nMÃ¬nh tháº¥y review á»Ÿ Ä‘Ã¢y cÃ³ â€˜ná»“i bÃ¡nh canh cuaâ€™ lÃ  láº¡ nÃªn láº·n lá»™i xÆ¡i ha Ä‘á»ƒ Ä‘i thá»­ ğŸ˜‰\\nQuÃ¡n náº±m trong háº»m, mÃ  theo map cÅ©ng dá»… kiáº¿m láº¯m Ã  ğŸ˜\\nNá»“i bÃ¡nh canh hoÃ nh trÃ¡ng láº¯m. Topping ngáº­p máº·t, toÃ n mÃ³n cháº¥t lÆ°á»£ng. TÃ´m to, cháº£ cÃ¡, trá»©ng cÃºt, thá»‹tâ€¦ nÃªm náº¿m ráº¥t á»•n ğŸ¤¤\\nMá»™t ná»“i 92k cÃ³ thá»ƒ Äƒn 2 ngÆ°á»i (no cÄƒng) hoáº·c 3 ngÆ°á»i náº¿u Äƒn Ã­t chÃºt. Gá»i thÃªm Ä‘Ä©a quáº©y 10k ğŸ¤‘\\nMÃ¬nh ghÃ© táº§m 5h chiá»u ngÃ y thÆ°á»ng, quÃ¡n Ä‘Ã´ng. Phá»¥c vá»¥ nhanh gá»n ğŸ‘\\nTeam mÃª bÃ¡nh canh cua lÃ  pháº£i thá»­ nha. Xa nhÃ  quÃ¡, chá»© ko mÃ¬nh ghÃ© hoÃ i ğŸ˜Š\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "sentiments = []\n",
    "for index,text in enumerate(reviewList):\n",
    "    sentiments.append(text[0])\n",
    "    texts.append(normalization(text[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveName = 'preprocessing/texts.txt'\n",
    "with open(saveName,'w') as writeFile:\n",
    "    for line in texts:\n",
    "        writeFile.write(str(line)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveName = 'preprocessing/sentiments.txt'\n",
    "with open(saveName,'w') as writeFile:\n",
    "    for line in sentiments:\n",
    "        writeFile.write(str(line)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
