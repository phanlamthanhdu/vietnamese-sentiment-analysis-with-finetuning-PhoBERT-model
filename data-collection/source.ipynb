{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "userAgents = [\n",
    "    'Mozilla/5.0 (X11; CrOS x86_64 8172.45.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.64 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hochiminh_districts = [\n",
    "    \"quán ăn quận 1\",\n",
    "    \"quán ăn quận 2\",\n",
    "    \"quán ăn quận 3\",\n",
    "    \"quán ăn quận 5\",\n",
    "    \"quán ăn quận 7\",\n",
    "    \"quán ăn quận 10\",\n",
    "    \"quán ăn quận Bình Thạnh\",\n",
    "    \"quán ăn quận Gò Vấp\",\n",
    "    \"quán ăn quận Phú Nhuận\",\n",
    "    \"quán ăn quận Tân Bình\",\n",
    "    \"quán ăn quận Thủ Đức\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanoi_districts = [\n",
    "    \"quán ăn quận Ba Đình\",\n",
    "    \"quán ăn quận Hoàn Kiếm\",\n",
    "    \"quán ăn quận Hai Bà Trưng\",\n",
    "    \"quán ăn quận Đống Đa\",\n",
    "    \"quán ăn quận Cầu Giấy\",\n",
    "    \"quán ăn quận Thanh Xuân\",\n",
    "    \"quán ăn quận Tây Hồ\",\n",
    "    \"quán ăn quận Hoàng Mai\",\n",
    "    \"quán ăn quận Long Biên\",\n",
    "    \"quán ăn quận Hà Đông\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "danang_districts = [\n",
    "    \"quán ăn quận Hải Châu\",\n",
    "    \"quán ăn quận Thanh Khê\",\n",
    "    \"quán ăn quận Sơn Trà\",\n",
    "    \"quán ăn quận Ngũ Hành Sơn\",\n",
    "    \"quán ăn quận Liên Chiểu\",\n",
    "    \"quán ăn quận Cẩm Lệ\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDomain = 'https://www.google.com/maps?hl=vi'\n",
    "driverdir = ChromeDriverManager().install()\n",
    "service = Service(executable_path=driverdir)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(baseDomain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. URL Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(keyword : str):\n",
    "    searchBox = driver.find_element(By.ID,\"searchboxinput\")   # Find search bar\n",
    "    searchBox.clear()                                         # Make search bar empty \"\"\n",
    "    searchBox.send_keys(keyword)                              # Pass keyword to search bar for searching\n",
    "    searchButton = driver.find_element(By.CLASS_NAME,\"mL3xi\") # Find lookup button\n",
    "    searchButton.click()                                      # Click on the lookup button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll(scrollTime : int):\n",
    "    # Find the window element to scroll\n",
    "    element = driver.find_element(By.XPATH,'//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[1]/div[1]')\n",
    "    while scrollTime > 0:\n",
    "        # Run JavaScript code\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", element)\n",
    "        time.sleep(2) # Sleep the program 2 seconds to avoid overlapping\n",
    "        scrollTime -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search('nhà hàng quán ăn quận 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlList = []\n",
    "for keyword in hochiminh_districts + hanoi_districts + danang_districts:\n",
    "   search(keyword)\n",
    "   time.sleep(2) # Wait for the process of searching\n",
    "   scroll(20)\n",
    "   \n",
    "   # Collect all results as a list\n",
    "   results = driver.find_elements(By.CLASS_NAME,\"hfpxzc\")\n",
    "   \n",
    "   for ele in results:\n",
    "      # Store the url of each result\n",
    "      urlList.append(ele.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveName = 'total-diner-urls.txt'\n",
    "with open(file=saveName,mode='w') as saveFile:\n",
    "    for ele in set(urlList):\n",
    "        saveFile.write(ele.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. URL Filter (restaurants at least 100 reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driverdir = ChromeDriverManager().install()\n",
    "service = Service(executable_path=driverdir)\n",
    "option = Options()\n",
    "option.add_argument(\"--headless=new\")\n",
    "\n",
    "\n",
    "def get_digits(text : str):\n",
    "    # This function will take only digits from a string \n",
    "    return int(''.join([c for c in text if c.isdigit()]))\n",
    "\n",
    "def filter_diner_urls(url : str):\n",
    "    # This function will filter the urls less than 100 reviews\n",
    "    driver = webdriver.Chrome(service=service,options=option)\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        rating = get_digits(driver.find_element(By.XPATH,\"//*[@class='F7nice ']\").find_elements(By.TAG_NAME,'span')[-1].text)\n",
    "        driver.quit()\n",
    "        return url if rating >= 100 else None\n",
    "    except:\n",
    "        driver.quit()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'raw-url/total-diner.txt'\n",
    "with open(fileName,'r') as readFile:\n",
    "    totalList = [ele.strip() for ele in readFile.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "saveFile = 'diner-at-least-100-reviews.txt'\n",
    "with open(saveFile,'w') as saveFile:\n",
    "    for i,ele in enumerate(totalList):\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            extractedData = filter_diner_urls(ele)\n",
    "            if extractedData:\n",
    "                saveFile.write(extractedData + '\\n')\n",
    "                saveFile.flush()\n",
    "                res.append(extractedData)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Review Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_extractor(url : str):\n",
    "    # Driver set up\n",
    "    driverdir = ChromeDriverManager().install()\n",
    "    service = Service(executable_path=driverdir)\n",
    "    option = Options()\n",
    "    option.add_argument(\"--headless=new\")\n",
    "    driver = webdriver.Chrome(service=service,options=option)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the process of requesting url\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        # Find the review tab element and click on it\n",
    "        driver.find_element(By.XPATH,\"//*[@class='hh2c6 ']\").click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        # If not exist, skip this url\n",
    "        driver.quit()\n",
    "        return None\n",
    "    \n",
    "    # Find the window of reviews and scroll down 10 times\n",
    "    scroller = driver.find_element(By.XPATH,\"//*[@class='m6QErb DxyBCb kA9KIf dS8AEf XiKgde ']\")\n",
    "    scrollTime = 10\n",
    "    for i in range(scrollTime):\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", scroller)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Collect all the reviews after scrolling\n",
    "    reviewList = driver.find_elements(By.XPATH,\"//*[@class='GHT2ce']\")\n",
    "    \n",
    "    res = []\n",
    "    for ele in reviewList:\n",
    "        # Try to click on the \"More\" button to fully render the text\n",
    "        try:\n",
    "            ele.find_element(By.XPATH,\"//*[@class='w8nwRe kyuRq']\").click()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            # Get the rating of review\n",
    "            rating = ele.find_element(By.CLASS_NAME,\"kvMYJc\").get_attribute('aria-label')\n",
    "            # Get the text of review\n",
    "            review = ele.find_element(By.CLASS_NAME,'MyEned').find_element(By.CLASS_NAME,\"wiI7pd\").text\n",
    "            res.append([rating,review])\n",
    "        except:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'diner-at-least-100-reviews.txt'\n",
    "with open(fileName,'r') as readFile:\n",
    "    urlList = [ele.strip() for ele in readFile.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveName = 'diner-reviews.txt'\n",
    "resumeName = 'resume.txt'\n",
    "\n",
    "# Set up resume mode\n",
    "try:\n",
    "    resumeLine = int(open(resumeName,'r').readline())\n",
    "except:\n",
    "    resumeLine = -1\n",
    "\n",
    "with open(saveName,'a') as saveFile:\n",
    "    for i,ele in enumerate(urlList):\n",
    "        if i < resumeLine:\n",
    "            continue\n",
    "        with open(resumeName,'w') as resumeFile:\n",
    "            resumeFile.write(str(i)) \n",
    "            resumeFile.flush()\n",
    "        try:\n",
    "            reviews = review_extractor(ele)\n",
    "            for rev in reviews:\n",
    "                saveFile.write(str(rev) + '\\n')\n",
    "                saveFile.flush()\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
